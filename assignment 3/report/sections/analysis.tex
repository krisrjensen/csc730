Let's begin by setting the stage for the OptiGrid code, by analyzing the pseudocode set out by Hinneburg and Keim [2]. Then the structure of the code will be outlined, followed by a detailed analysis of each function and its purpose.\newline
% Compare this snippet from assignment%203/report/sections/discussion.tex:
\begin{tcolorbox}[breakable, title={$OptiGrid(dataset~D,~q,~min\_cut\_score)$}]
    %use numbers list
    \footnotesize     
    
    \begin{enumerate}[label=\arabic*., leftmargin=0.2cm]
        \item Determine a set of contracting projections P = \{$P_0$, . . ., $P_k$\}
        \item Calculate all projections of the dataset $D \to P_{0}(D)$, . . ., $P_{k}(D)$
        \item Initialize a list of cutting planes $BEST\_CUTS \leftarrow \emptyset, CUT \leftarrow \emptyset$
        \item FOR i=0 TO k Do
        \begin{enumerate}[label=\alph*., leftmargin=0.2cm]
            \item CUT $\leftarrow$ Determine best\_local\_cuts($P_i(D)$)
            \item CUT\_SCORE $\leftarrow$ score\_best\_local\_cuts($P_i(D)$)
            \item Insert all cutting planes with a score $\geq$ min\_cut\_score into $BEST\_CUTS$            
        \end{enumerate}
        END FOR
        \item IF $BEST\_CUT = \emptyset$ THEN RETURN $D$ as a cluster
        \item Determine the $q$ cutting planes with highest score from $BEST\_CUTS$ and delete the rest
        \item Construct a Multidimensional Grid $G$ defined by the cutting planes in $BEST\_CUTS$ and insert all data points $x \in D$ into $G$
        \item Determine clusters, i.e. determine the highly populated grid cells in G and add them to the set of cluster C
        \item REFINE(C)
        \item FOREACH Cluster $C_i \in C$ DO\newline
        OptiGrid($C_i$, q, min\_cut\_score)
    \end{enumerate}    
\end{tcolorbox}
\normalsize

\subsection{Functions of class OptiGrid}
\begin{enumerate}    
    \item $\mathbf{\_\_init\_\_(d, q, max\_cut\_score, ...)}$\newline
    {The $\_\_init\_\_$ functions acts as the class constructor and is called automatically upon instantiation. It initializes the class variables and sets the default values for the parameters. 
    The parameters include dataset dimension (\textbf{d}), number of cuts per iteration (\textbf{q}), the max cut score density of a plane ({$\mathbf{max\_cut\_score}$}), 
    noise level for dataset($\mathbf{noise\_level}$), several parameters related to the kernel density estimation including bandwidth ($\mathbf{kde\_bandwidth}$), 
    grid ticks ($\mathbf{kde\_grid\_ticks}$), sample size ($\mathbf{kde\_num\_samples}$), tolerance ($\mathbf{kde\_atol}$) and ($\mathbf{kde\_rtol}$), 
    and finally an argument for turning on or off output (\textbf{verbose}) . This function sets the initial conditions of the OptiGrid algorithm.}
    \item $\mathbf{fit(data, weights)}$\newline
    {The fit function is the function that is called to start the OptiGrid algorithm. 
    It is the main function that calls all the other functions in the class.
    The fit function takes in the dataset and the initial weights as a parameter.\par
    The fit function first records the data length and initializes the list of clusters. Following this setup, the $\_iteration$ method is called which begins the OptiGrid algorithm.}
    
    \item $\mathbf{\_iteration(data, weights, cluster\_indices, ...)}$\newline
    {The first step in the $\_iteration$ function, a pseudo-private method, is to create an empty list of cuts. 
    The list of cuts is generated by looping through all dimensions of the dataset and calling the $\_find\_best\_cuts$ function. This loop will generate all cutting planes from d=1 to d=len(self.d). 
    The $current\_dimension$ parameter sent to the $\_find\_best\_cuts$ function is incremented by 1 each iteration.\par
    If the list of cuts is empty, then the function returns the dataset as a cluster and indicate there are no further cutting planes available for this dataset. 
    If the list of cuts is not empty, the list of cutting planes is sorted by score. 
    The cutting planes discovered in the previous step are then passed to GridLevel to construct a multidimensional grid. 
    The first call to GridLevel is made with the cutting planes list to construct the grid for this iteration in the recursive call stack. 
    Then a grid of cutting planes is created from the data and clusters. This grid data contains the information if the data is left or right of the cutting plane and encoded as either 0 or ${2^i}$\par
    At this point, the algorithm has created a grid and the data is labeled as being left or right, or above or below the plane. 
    This data needs to be iterated through to recursively apply the same process to the left and right datasets if the size of cluster exceeds 0.
    When the first call to $self.\_iteration$ is made, the algorithm will continue to split the dataset until the dataset is no longer able to be split. 
    Finally, when this first call returns, the algorithm will have found all the clusters in the dataset.\par
    This function is the top level code that implements the pseudocode for the OptiGrid algorithm. Lines 66 through 68 accomplish pseudocode lines 1 through 6. Line 81 accomplishes psuedocode line 7. Line 83 fulfills pseudocode line 8. Lines 85 through 96 accomplish psuedocode step 9 and 10.}       


    \item $\mathbf{\_fill\_grid(data, cluster\_indices,cuts)}$\newline
    {The semi-private method $\_fill\_grid$ is called to fill the grid with the data and cluster indices. Reviewing the pseudocode, this function accomplishes step 8. 
    A labelling scheme described in definition 5 and definition 6 of [2] is used to label the data bifurcated by the cutting planes. 
    The method loops through all the cuts and sets the $grid\_index$ location to either 0 or ${2^i}$ depending on the conditional broadcasting that determines on which side of the plane the datapoints lie.}
    \item $\mathbf{\_create\_cuts\_kde(data, cluster\_indices,}$\newline $\mathbf{~~~~cuts,  ... )}$\newline
    {The semi-private method $\_create\_cuts\_kde$ is called to create the cuts along each dimension of the data.
    The data is first estimated by the $\_estimate\_distribution$ function along the current dimension using a kernel-density estimation.
    The peaks of the kernel-density estimation are found using the $\_find\_peaks\_distribution$ function.
    If there are no peaks in the distribution, then no further cuts are to be made.
    If there are peaks in the distribution, they are sorted so that only $q$ of the peaks are used to make the cuts.
    The remaining peaks are then used by the $\_find\_best\_cuts$ function for the current dimension.
    Based on the pseudocode, this function accomplishes steps 4a through 4c.}
    \item $\mathbf{\_find\_best\_cuts(grid, kde, peaks, }$\newline $\mathbf{~~~~current\_dimension)}$\newline
    {The semi-private method $\_find\_best\_cuts$ is called to find the best cuts for a dimension based on the density estimation previously computed.
    To find the best peaks, each set of pairs of peaks is searched between. The best cut for each pair is recorded in a $best\_cuts$ as the cut location, the dimension the cut was in, and the density at the point of cut.
    This results in a list of cuts at each of the peak minimums.}
    \item $\mathbf{\_find\_peaks\_distribution(kde)}$\newline
    {The semi-private method $\_find\_peaks\_distribution$ is called to locate the indices of peaks for the kde along a given dimension.
    A list of indices is assembled by iterating through the iteration while tracking the previous, current, and next value along the distribution.
    If the previous and next values are both less than that of the current value, then the current index is added to the list of peaks.}
    \item $\mathbf{\_estimate\_distribution( data, }$\newline $\mathbf{~~~~ cluster\_indices, current\_dimension,}$\newline $\mathbf{~~~~  percentage\_of\_values,~weights )}$\newline
    {The semi-private mathod $\_estimate\_distribution$ is called to perform a kernel-based estimation of the data along a certain dimension.
    The data is passed through numpy's implementation of gaussian kde using a random sample of the points in the current cluster and a bandwidth scaled by the standard deviation of the random sample.
    The range of the data is arranged into a linspace and the density along that range is evaluated according to the kde calculated.
    This results in a range of data and the density of that range scaled by the total amount of data used.}
    \item $\mathbf{score\_samples}$\newline
    {The method $\_score\_samples$ is called to predict the cluster for a set of data samples.
    For each sample in the list of samples, the function creates a list of each score as calculated by the $\_score\_sample$ function.}
    \item $\mathbf{\_score\_sample}$\newline
    {The semi-private method $\_score\_sample$ is called to predict the cluster index that a sample belongs to.
    Recursing through the tree-like structure of grid level, the sublevel of the sample is found until it results in the lowest sublevel of which the sample is assigned the cluster index.}
\end{enumerate}

\subsection{Functions of class GridLevel}
\begin{enumerate}    
    \item $\mathbf{\_\_init\_\_}$\newline
    {}
    \item $\mathbf{add\_subgrid}$\newline
    {}
    \item $\mathbf{get\_sublevel}$\newline
    {}
\end{enumerate}


