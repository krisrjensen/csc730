{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found following cuts: [(-0.41783537483156374, 0, 2.236518682454137e-05)]\n",
      "Evaluating subgrid: 50.00% of datapoints\n",
      "Found cluster 0: 50.00% of datapoints\n",
      "Evaluating subgrid: 50.00% of datapoints\n",
      "Found cluster 1: 50.00% of datapoints\n",
      "Optigrid found 2 clusters.\n",
      "Cluster 0: Mean=[-5.00335437 -4.98570265  0.9999046 ], Std=[0.99891199 0.99446087 0.22298978]\n",
      "Cluster 1: Mean=[ 5.00077602e+00  1.15342401e-03 -9.97732119e-01], Std=[1.00359211 0.9982854  0.22250921]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from optigrid import optigrid\n",
    "\n",
    "\n",
    "\n",
    "# First, generate two separate normal distributions and noise\n",
    "normal1_mean = [-5, -5, 1]\n",
    "normal1_cov = [[1, 0, 0], [0, 1, 0], [0, 0, 0.05]]\n",
    "normal1_samples = 10000\n",
    "normal1 = np.random.multivariate_normal(mean=normal1_mean, cov=normal1_cov, size=normal1_samples)\n",
    "\n",
    "normal2_mean = [5, 0, -1]\n",
    "normal2_cov = [[1, 0, 0], [0, 1, 0], [0, 0, 0.05]]\n",
    "normal2_samples = 20000\n",
    "normal2 = np.random.multivariate_normal(mean=normal2_mean, cov=normal2_cov, size=normal2_samples)\n",
    "\n",
    "noise_low = [-10, -10, -10]\n",
    "noise_high = [10, 10, 10]\n",
    "noise_samples = 10000\n",
    "noise = np.random.uniform(low=noise_low, high=noise_high, size=(noise_samples, 3))\n",
    "\n",
    "data = np.concatenate((normal1, normal2))#, noise))\n",
    "\n",
    "# Weight the samples from the first population twice as high\n",
    "weights = np.array([2] * normal1_samples + [1] * normal2_samples)\n",
    "\n",
    "# Now we want to standard scale our data. Although it is not necessary, it is recommended for better selection of the parameters and uniform importance of the dimensions.\n",
    "data_scaled = (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n",
    "\n",
    "# Next, chose the parameters\n",
    "d = 3 # Number of dimensions\n",
    "q = 1 # Number of cutting planes per step\n",
    "noise_level = 0.1\n",
    "max_cut_score = 0.3\n",
    "bandwidth = 0.1\n",
    "\n",
    "# Fit Optigrid to the data\n",
    "optigrid_test = optigrid.Optigrid(d=d, q=q, max_cut_score=max_cut_score, noise_level=noise_level, kde_bandwidth=bandwidth, verbose=True)\n",
    "optigrid_test.fit(data_scaled, weights=weights)\n",
    "### Output: \n",
    "###     In current cluster: 47.08% of datapoints\n",
    "###     In current cluster: 52.92% of datapoints\n",
    "###     Optigrid found 2 clusters.\n",
    "\n",
    "for i, cluster in enumerate(optigrid_test.clusters):\n",
    "    cluster_data = np.take(data, cluster, axis=0) # Clusters are stored as indices pointing to the original data\n",
    "    print(\"Cluster {}: Mean={}, Std={}\".format(i, np.mean(cluster_data, axis=0), np.std(cluster_data, axis=0)))\n",
    "### Output: \n",
    "###     Cluster 0: Mean=[-5.03474967 -3.3355985   0.6569438 ], Std=[1.79700025 4.11403245 3.33377444]\n",
    "###     Cluster 1: Mean=[ 4.92505754  0.05634452 -0.62898176], Std=[1.92237979 3.49116619 3.46671477]\n",
    "\n",
    "# Draw a 10 values from both normals and score it with optigrid after normalization\n",
    "sample_size = 10\n",
    "sample1 = np.random.multivariate_normal(normal1_mean, normal1_cov, sample_size)\n",
    "sample2 = np.random.multivariate_normal(normal2_mean, normal2_cov, sample_size)\n",
    "sample = np.concatenate((sample1, sample2))\n",
    "sample = (sample - np.mean(data)) / np.std(data)\n",
    "\n",
    "result = optigrid_test.score_samples(sample)\n",
    "print(result)\n",
    "### Output: \n",
    "###     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "### The first ten values belong to the zeroth cluster and the latter ten to the second cluster as expected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
